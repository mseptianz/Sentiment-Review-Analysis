{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "import numpy as numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review & Rating Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_urls(url_main):\n",
    "    product_urls = []\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    try:\n",
    "        driver.get(url_main)\n",
    "        sleep(2)\n",
    "\n",
    "        # Scroll the page to load all links\n",
    "        for _ in range(15):  # Scroll n times\n",
    "            driver.execute_script(\"window.scrollBy(0, 250)\")\n",
    "            sleep(1)\n",
    "\n",
    "        # Get the page source after scrolling\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        # Find all divs with the class containing product information\n",
    "        product_divs = soup.find_all('div', {\"class\": \"css-1asz3by\"})\n",
    "\n",
    "        # Extract href from nested <a> tags inside the divs\n",
    "        for div in product_divs:\n",
    "            a_tag = div.find('a')  # Locate the <a> tag inside the div\n",
    "            if a_tag and a_tag.get('href'):\n",
    "                product_urls.append(a_tag['href'])\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return product_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews_and_ratings(product_urls):\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    try:\n",
    "        for product_url in product_urls:\n",
    "            print(f\"Processing: {product_url}\")\n",
    "            driver.get(product_url)\n",
    "\n",
    "            while True:\n",
    "                for _ in range(20):\n",
    "                    driver.execute_script(\"window.scrollBy(0, 250)\")\n",
    "                    sleep(1)\n",
    "\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "                for product in soup.find_all('div', {\"class\": \"css-1k41fl7\"}):\n",
    "                    review_element = product.find('span', {\"data-testid\": \"lblItemUlasan\"})\n",
    "                    reviews.append(review_element.get_text() if review_element else 'None')\n",
    "\n",
    "                    rating_element = product.find('div', {\"class\": \"rating\"})\n",
    "                    ratings.append(rating_element.get('aria-label') if rating_element else 'None')\n",
    "\n",
    "                try:\n",
    "                    next_button_container = driver.find_element(By.CLASS_NAME, \"css-1xqkwi8\")\n",
    "                    next_button = next_button_container.find_element(\n",
    "                        By.XPATH, './/button[contains(@class, \"css-16uzo3v-unf-pagination-item\") and @aria-label=\"Laman berikutnya\"]'\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    sleep(2)\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(\"No more pages to navigate for this product.\")\n",
    "                    break\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    print(f\"Scraped {len(reviews)} reviews and {len(ratings)} ratings.\")  # Debugging output\n",
    "    data = pd.DataFrame({'Review': reviews, 'Rating': ratings})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url_main):\n",
    "    urls = []\n",
    "\n",
    "    for url in url_main:\n",
    "        # Get the product URLs from the main page\n",
    "        product_urls = get_product_urls(url)\n",
    "        for urll in product_urls:    \n",
    "            urls.append(urll)\n",
    "\n",
    "    # Scrape reviews and ratings for each product\n",
    "    data = scrape_reviews_and_ratings(urls)\n",
    "\n",
    "    # Optionally, save the data to a CSV file\n",
    "    data.to_csv(\"reviews.csv\", index=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://www.tokopedia.com/xiaomi/official-poco-x6-pro-5g-dimensity-8300-ultra-120hz-fiow-amoled-67w-t-grey-12-512g-ed3b0?extParam=src%3Dshop%26whid%3D13418340\n",
      "No more pages to navigate for this product.\n",
      "Processing: https://www.tokopedia.com/xiaomi/official-poco-c65-ram-hingga-16-gb-prosesor-kencang-helio-g85-90hz-black-8-256g-5d9be?extParam=src%3Dshop%26whid%3D13418340\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: timeout: Timed out receiving message from renderer: 300.000\n  (Session info: chrome=122.0.6261.112)\nStacktrace:\n\tGetHandleVerifier [0x00007FF72EF5AD02+56930]\n\t(No symbol) [0x00007FF72EECF602]\n\t(No symbol) [0x00007FF72ED842E5]\n\t(No symbol) [0x00007FF72ED71FDF]\n\t(No symbol) [0x00007FF72ED71E11]\n\t(No symbol) [0x00007FF72ED70625]\n\t(No symbol) [0x00007FF72ED710AF]\n\t(No symbol) [0x00007FF72ED7DF3E]\n\t(No symbol) [0x00007FF72ED9009E]\n\t(No symbol) [0x00007FF72ED94E5A]\n\t(No symbol) [0x00007FF72ED71600]\n\t(No symbol) [0x00007FF72ED8FECD]\n\t(No symbol) [0x00007FF72EE080BD]\n\t(No symbol) [0x00007FF72EDEBA43]\n\t(No symbol) [0x00007FF72EDBD438]\n\t(No symbol) [0x00007FF72EDBE4D1]\n\tGetHandleVerifier [0x00007FF72F2D6F8D+3711213]\n\tGetHandleVerifier [0x00007FF72F3304CD+4077101]\n\tGetHandleVerifier [0x00007FF72F32865F+4044735]\n\tGetHandleVerifier [0x00007FF72EFF9736+706710]\n\t(No symbol) [0x00007FF72EEDB8DF]\n\t(No symbol) [0x00007FF72EED6AC4]\n\t(No symbol) [0x00007FF72EED6C1C]\n\t(No symbol) [0x00007FF72EEC68D4]\n\tBaseThreadInitThunk [0x00007FFDD6B5259D+29]\n\tRtlUserThreadStart [0x00007FFDD7F0AF38+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m---> 40\u001b[0m         \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwindow.scrollBy(0, 250)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m         sleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m     html \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n",
      "File \u001b[1;32md:\\Miniconda\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:414\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    411\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    412\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Miniconda\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Miniconda\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: timeout: Timed out receiving message from renderer: 300.000\n  (Session info: chrome=122.0.6261.112)\nStacktrace:\n\tGetHandleVerifier [0x00007FF72EF5AD02+56930]\n\t(No symbol) [0x00007FF72EECF602]\n\t(No symbol) [0x00007FF72ED842E5]\n\t(No symbol) [0x00007FF72ED71FDF]\n\t(No symbol) [0x00007FF72ED71E11]\n\t(No symbol) [0x00007FF72ED70625]\n\t(No symbol) [0x00007FF72ED710AF]\n\t(No symbol) [0x00007FF72ED7DF3E]\n\t(No symbol) [0x00007FF72ED9009E]\n\t(No symbol) [0x00007FF72ED94E5A]\n\t(No symbol) [0x00007FF72ED71600]\n\t(No symbol) [0x00007FF72ED8FECD]\n\t(No symbol) [0x00007FF72EE080BD]\n\t(No symbol) [0x00007FF72EDEBA43]\n\t(No symbol) [0x00007FF72EDBD438]\n\t(No symbol) [0x00007FF72EDBE4D1]\n\tGetHandleVerifier [0x00007FF72F2D6F8D+3711213]\n\tGetHandleVerifier [0x00007FF72F3304CD+4077101]\n\tGetHandleVerifier [0x00007FF72F32865F+4044735]\n\tGetHandleVerifier [0x00007FF72EFF9736+706710]\n\t(No symbol) [0x00007FF72EEDB8DF]\n\t(No symbol) [0x00007FF72EED6AC4]\n\t(No symbol) [0x00007FF72EED6C1C]\n\t(No symbol) [0x00007FF72EEC68D4]\n\tBaseThreadInitThunk [0x00007FFDD6B5259D+29]\n\tRtlUserThreadStart [0x00007FFDD7F0AF38+40]\n"
     ]
    }
   ],
   "source": [
    "urlss = ['https://www.tokopedia.com/samsung/etalase/mobiles',\n",
    "       'https://www.tokopedia.com/xiaomi/etalase/mobile']\n",
    "\n",
    "urls = []\n",
    "\n",
    "for url in urlss:\n",
    "    # Get the product URLs from the main page\n",
    "    product_urls = get_product_urls(url)\n",
    "    for urll in product_urls:    \n",
    "        urls.append(urll)\n",
    "\n",
    "reviews = []\n",
    "ratings = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    for product_url in urls:\n",
    "        print(f\"Processing: {product_url}\")\n",
    "        driver.get(product_url)\n",
    "\n",
    "        while True:\n",
    "            for _ in range(20):\n",
    "                driver.execute_script(\"window.scrollBy(0, 250)\")\n",
    "                sleep(1)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "            for product in soup.find_all('div', {\"class\": \"css-1k41fl7\"}):\n",
    "                review_element = product.find('span', {\"data-testid\": \"lblItemUlasan\"})\n",
    "                reviews.append(review_element.get_text() if review_element else 'None')\n",
    "\n",
    "                rating_element = product.find('div', {\"class\": \"rating\"})\n",
    "                ratings.append(rating_element.get('aria-label') if rating_element else 'None')\n",
    "\n",
    "            try:\n",
    "                next_button_container = driver.find_element(By.CLASS_NAME, \"css-1xqkwi8\")\n",
    "                next_button = next_button_container.find_element(\n",
    "                    By.XPATH, './/button[contains(@class, \"css-16uzo3v-unf-pagination-item\") and @aria-label=\"Laman berikutnya\"]'\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "                driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                sleep(2)\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                print(\"No more pages to navigate for this product.\")\n",
    "                break\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "print(f\"Scraped {len(reviews)} reviews and {len(ratings)} ratings.\")  # Debugging output\n",
    "data = pd.DataFrame({'Review': reviews, 'Rating': ratings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 3800 reviews and 3800 ratings.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scraped {len(reviews)} reviews and {len(ratings)} ratings.\")  # Debugging output\n",
    "data = pd.DataFrame({'Review': reviews, 'Rating': ratings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"reviews_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('product_reviews.csv')\n",
    "data2 = pd.read_csv('reviews_1.csv')\n",
    "data3 = pd.read_csv('reviews_2.csv')\n",
    "data4 = pd.read_csv('reviews_3.csv')\n",
    "\n",
    "data5 = pd.concat([data1, data2, data3, data4])\n",
    "\n",
    "data5.to_csv('data_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "names, prices, ratings_overall, solds= [], [], [], []\n",
    "\n",
    "url = 'https://www.tokopedia.com/officialinfinix/etalase/note-series'\n",
    "driver.get(url)\n",
    "\n",
    "# Scroll to load products\n",
    "for scroll in range(6):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(1)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "for x in soup.find_all('div', {'class': 'css-1sn1xa2'}):\n",
    "    try:\n",
    "        # Get product name and price\n",
    "        name = x.find('div', {'class': 'prd_link-product-name css-3um8ox'})\n",
    "        price = x.find('div', {'class': 'prd_link-product-price css-h66vau'})\n",
    "        rating_overall = x.find('span', {'class' : 'prd_rating-average-text css-t70v7i'})\n",
    "        sold = x.find('span', {'class': 'prd_label-integrity css-1sgek4h'})\n",
    "\n",
    "        names.append(name.get_text() if name else None)\n",
    "        prices.append(price.get_text() if price else None)\n",
    "        ratings_overall.append(rating_overall.get_text() if rating_overall else None)\n",
    "        solds.append(sold.get_text() if sold else None)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "print('Scraping complete.')\n",
    "\n",
    "print(f'length of names : {len(names)}')\n",
    "print(f'length of prices : {len(prices)}')\n",
    "print(f'length of ratings overall : {len(ratings_overall)}')\n",
    "print(f'length of solds : {len(solds)}')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands, ram, rom= [], [], []\n",
    "brands.extend(['infinix' for i in range(7)])\n",
    "ram.extend(['0' for i in range(7)])\n",
    "rom.extend(['0' for i in range(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_analyst(data):\n",
    "    data = data.dropna()\n",
    "    data['price'] = [number[2:] for number in data.price]\n",
    "    data['price'] = [number.replace('.', '') for number in data.price]\n",
    "    data['sold'] = [number.replace('+ terjual', '') for number in data.sold]\n",
    "    data['sold'] = [number.replace(' terjual', '') for number in data.sold]\n",
    "    \n",
    "    for number in data.sold:\n",
    "        k = ['1rb', '2rb', '3rb', '4rb', '5rb', '6rb', '7rb', '8rb', '9rb', '10rb']\n",
    "        if number in k:\n",
    "            data['sold'] = data['sold'].replace(number, number[:1] + '000')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'name':names, 'price':prices, 'rating':ratings_overall, 'sold':solds, 'brand':brands, 'ram':ram, 'rom':rom})\n",
    "data = clean_analyst(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_ram = data['name'].str.extract(r'(\\d+)/')[0]\n",
    "extracted_rom = data['name'].str.extract(r'/(\\d+)GB')[0]\n",
    "\n",
    "data.loc[data['ram']=='0', 'ram'] = extracted_ram\n",
    "data.loc[data['rom']=='0', 'rom'] = extracted_rom\n",
    "\n",
    "data['ram'] = data['ram'].fillna(data['name'].str.extract(r'(\\d+)GB')[0])\n",
    "data['rom'] = data['rom'].fillna(data['name'].str.extract(r'/(\\d+)\\)')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([df, data], ignore_index=True)\n",
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv('analyst.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
